{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TP réalisé par Rachel Blin dans le cadre du cours d'Alexandrina Rogozan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codage de Huffman\n",
    "\n",
    "L'objectif de ce TP est de réaliser le codage de Huffman pour le message suivant :  \n",
    "  \n",
    "\"*Il n'existe que deux choses infinies, l'univers et la bêtise humaine... mais pour l'univers, je n'ai pas de certitude absolue.*\" (Albert Einstein)\n",
    "\n",
    "## Simplification de la séquence\n",
    "\n",
    "Afin de rendre la séquence plus simple à encoder, nous allons tout d'abord transformer la phrase de telle sorte à ce qu'elle ne contienne que des caractères présents dans les 26 lettres de l'alphabet en minuscule, sans accents, ainsi que les espaces.\n",
    "\n",
    "La message à encoder devient donc :  \n",
    "  \n",
    "\"*il nexiste que deux choses infinies lunivers et la betise humaine mais pour lunivers je nai pas de certitude absolue*\n",
    "\n",
    "## Classification des symboles de la séquence par ordre d'occurences croissants\n",
    "\n",
    "La première étape du codage de Huffman est de classer les symboles de la séquence à encoder par nombre d'occurences croissants.  \n",
    "  \n",
    "1) Dans un premier temps, répertoriez tous les caractères présents dans le message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = \"il nexiste que deux choses infinies lunivers et la betise humaine mais pour lunivers je nai pas de certitude absolue\"\n",
    "\n",
    "def unique(message):\n",
    "    \"\"\" Returs all the uninque char in a string.\n",
    "    \n",
    "    # Argument:\n",
    "        - message: The string to extract the unique characters from\n",
    "        \n",
    "    # Returns:\n",
    "        - A list containing all the unique characters in the input string.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Calculez maintenant le nombre d'occurences de chacun de ces caractères dans le message et rangez ces occurences par nombre croissant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import collections\n",
    "\n",
    "def occurences(message):\n",
    "    \"\"\" Counts the number of occurencies in a given message.\n",
    "    \n",
    "    # Argument:\n",
    "        - message: The string from which we wish to count the occurencies of the chars.\n",
    "    \n",
    "    # Returns:\n",
    "        - A dict containing the chars as keys and the number of occurencies of each chars.\n",
    "    \"\"\"\n",
    "\n",
    "def order_by_values(dictionary):\n",
    "    \"\"\" Helper function to order a dictionnary by its values.\n",
    "    \n",
    "    # Argument:\n",
    "        - dictionary: The dictionary to order.\n",
    "        \n",
    "    # Returns:\n",
    "        - An ordered list of tuples containing as first value the character and as second the number of occurencies\n",
    "    \n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des symboles en deux sous-groupes\n",
    "\n",
    "Une fois les symboles classés par ordre d'occurence décroissante, on va maintenant créer un arbre dont les feuilles sont les cractères présents dans le message avec leur nombre d'occurences dans le message. Afin de créer cet arbre, on va d'abord chercher les noeuds ayant le plus petit nombre d'occurences et les accrocher à un noeud dont l'occurence est la somme des occurences des deux noeuds. On va répéter cette opération de sorte à ce qu'il n'y ait plus qu'un seul noeud dans l'arbre.\n",
    "\n",
    "__Exemple__ :  \n",
    "Pour une séquence contenant les caractères (a, b, c, d, e) d'occurences respectives (1, 1, 2, 2, 3) on obtient le graphe suivant : \n",
    "\n",
    "![graphe](TP_Huffman.png)\n",
    "\n",
    "Ce qui donne donc le codage de Huffman suivant : \n",
    "\n",
    "| Caractère | Nombre d'occurences | Code Huffman |\n",
    "|-----------|---------------------|-------------------|\n",
    "| a         | 1                   | 111               |\n",
    "| b         | 1                   | 110               |\n",
    "| c         | 2                   | 10                |\n",
    "| d         | 2                   | 01                |\n",
    "| e         | 3                   | 00                |\n",
    "\n",
    "3) Créez le graphe de séparation des symboles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une structure de données de type arbre\n",
    "class Tree(object):\n",
    "    \"\"\" Tree object.\"\"\"\n",
    "    def __init__(self, g=None, d=None, data=None):\n",
    "        \"\"\" Init function.\n",
    "        \n",
    "        # Arguments:\n",
    "            - g: The left node of the tree.\n",
    "            - d: The right node of the tree.\n",
    "            - data: The data to be held in the node.\n",
    "        \"\"\"\n",
    "        self.g = g\n",
    "        self.d = d\n",
    "        self.data = data\n",
    "\n",
    "def update_list_node(list_node, new_node):\n",
    "    \"\"\" Adds a node in the correct place in an ordered list of nodes.\n",
    "    \n",
    "    # Arguments:\n",
    "        - list_node: The list of nodes we want to add the node to.\n",
    "        - new_node: The node to be added.\n",
    "    \n",
    "    # Returns:\n",
    "        - The list with the added node.\n",
    "    \"\"\"\n",
    "\n",
    "def Huffman(sorted_occurences):\n",
    "    \"\"\" Creates the Huffman tree.\n",
    "    \n",
    "    # Argument:\n",
    "        - sorted_occurences: The sorted occurencies of the message we wish to encode.\n",
    "    \n",
    "    # Returns:\n",
    "        - The root of the Huffman tree.\n",
    "    \"\"\"\n",
    "        \n",
    "def get_dict_codage(graph):\n",
    "    \"\"\" Creates the coding dictionnary.\n",
    "    \n",
    "    # Argument:\n",
    "        - graph: The root of the Huffman tree.\n",
    "    \n",
    "    # Returns:\n",
    "        - A coding dictionary.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Effectuez maintenant le codage de Huffman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_message(m, dict_Huffman):\n",
    "    \"\"\" Encodes a given message.\n",
    "    \n",
    "    # Arguments:\n",
    "        - m: The message to encode.\n",
    "        - dict_Huffman: The coding dictionary.\n",
    "    \n",
    "    # Returns:\n",
    "        - The encoded message.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation de l'encodage \n",
    "\n",
    "En se basant sur le codage binaire des caractères de la table ASCII, le message de départ est le suivant :  \n",
    "\"0100100101001100001000000100111001000101010110000100100101010011010101000100010100100000010100010101010101000101001000000100010001000101010101010101100000100000010000110100100001001111010100110100010101010011001000000100100101001110010001100100100101001110010010010100010101010011001000000100110001010101010011100100100101010110010001010101001001010011001000000100010101010100001000000100110001000001001000000100001001000101010101000100100101010011010001010010000001001000010101010100110101000001010010010100111001000101001000000100110101000001010010010101001100100000010100000100111101010101010100100010000001001100010101010100111001001001010101100100010101010010010100110010000001001010010001010010000001001110010000010100100100100000010100000100000101010011001000000100010001000101001000000100001101000101010100100101010001001001010101000101010101000100010001010010000001000001010000100101001101001111010011000101010101000101\"    \n",
    "\n",
    "Pour rappel, le message encodé par la méthode de Shannon-Fano est le suivant :    \n",
    "\n",
    "\"10010011110101101000001100110000100010111000000000111011100100010101100000111000010000011001001100010110001110010101000000011001010110011011000110011011010110010001001010010110001110101000110011010011100010110101000100110001011100001101100011001001100101011011100011001001100110001100011100100101100101110011011010110010001001010010110001100000011011101010100110011100011101001100011001000101110000101010010101000100101000011001000101110100100010110000010010011011101\"    \n",
    "\n",
    "5) Que peut-on dire du rôle du codage de Huffman? Est-il plus ou moins efficace que le codage de Shannon-Fano? Vous calculerez le taux de compression pour illustrer votre réponse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaire = \"0100100101001100001000000100111001000101010110000100100101010011010101000100010100100000010100010101010101000101001000000100010001000101010101010101100000100000010000110100100001001111010100110100010101010011001000000100100101001110010001100100100101001110010010010100010101010011001000000100110001010101010011100100100101010110010001010101001001010011001000000100010101010100001000000100110001000001001000000100001001000101010101000100100101010011010001010010000001001000010101010100110101000001010010010100111001000101001000000100110101000001010010010101001100100000010100000100111101010101010100100010000001001100010101010100111001001001010101100100010101010010010100110010000001001010010001010010000001001110010000010100100100100000010100000100000101010011001000000100010001000101001000000100001101000101010100100101010001001001010101000101010101000100010001010010000001000001010000100101001101001111010011000101010101000101\"\n",
    "\n",
    "message_Shanon_Fano = \"10010011110101101000001100110000100010111000000000111011100100010101100000111000010000011001001100010110001110010101000000011001010110011011000110011011010110010001001010010110001110101000110011010011100010110101000100110001011100001101100011001001100101011011100011001001100110001100011100100101100101110011011010110010001001010010110001100000011011101010100110011100011101001100011001000101110000101010010101000100101000011001000101110100100010110000010010011011101\"\n",
    "\n",
    "def taux_compression(longueur_source, longueur_encode):\n",
    "    \"\"\" Computes the compression rate of the encoded message.\n",
    "    \n",
    "    # Arguments:\n",
    "        - longueur_source: The lenght of the binary message before being encoded.\n",
    "        - dict_Huffman: The lenght of the binary message after being encoded.\n",
    "    \n",
    "    # Returns:\n",
    "        - The compression rate.\n",
    "    \"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author_info": {
   "class": "Information Theory",
   "information": "Suject, code and corrections are made by Rachel Blin, the class responsible is Alexandrina Rogozan",
   "name": "Rachel Blin"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
